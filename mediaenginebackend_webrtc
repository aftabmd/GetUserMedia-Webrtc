# HG changeset patch
# Parent 1bc4542bb06ddcb905239a9e8de3841243a77435
 Bug 691234 - WebRTC media engine backend patch v1.0

diff --git a/content/media/Makefile.in b/content/media/Makefile.in
--- a/content/media/Makefile.in
+++ b/content/media/Makefile.in
@@ -16,16 +16,19 @@ XPIDL_MODULE = content_media
 
 XPIDLSRCS = \
   nsIDOMMediaStream.idl \
   $(NULL)
 
 EXPORTS = \
   AudioSegment.h \
   FileBlockCache.h \
+  MediaEngine.h \
+  MediaEngineDefault.h \
+  MediaEngineWebrtc.h \
   MediaResource.h \
   MediaSegment.h \
   MediaStreamGraph.h \
   nsAudioAvailableEventManager.h \
   nsBuiltinDecoder.h \
   nsBuiltinDecoderStateMachine.h \
   nsBuiltinDecoderReader.h \
   nsDOMMediaStream.h \
@@ -36,16 +39,18 @@ EXPORTS = \
   TimeVarying.h \
   VideoFrameContainer.h \
   VideoUtils.h \
   VideoSegment.h \
   $(NULL)
 
 CPPSRCS = \
   AudioSegment.cpp \
+  MediaEngineDefault.cpp \
+  MediaEngineWebrtc.cpp \
   FileBlockCache.cpp \
   MediaResource.cpp \
   MediaStreamGraph.cpp \
   nsAudioAvailableEventManager.cpp \
   nsBuiltinDecoder.cpp \
   nsBuiltinDecoderStateMachine.cpp \
   nsBuiltinDecoderReader.cpp \
   nsDOMMediaStream.cpp \
@@ -87,16 +92,17 @@ endif
 
 ifdef ENABLE_TESTS
 PARALLEL_DIRS += test
 endif
 
 FORCE_STATIC_LIB = 1
 
 include $(topsrcdir)/config/config.mk
+include $(topsrcdir)/media/webrtc/webrtc-config.mk
 include $(topsrcdir)/ipc/chromium/chromium-config.mk
 include $(topsrcdir)/config/rules.mk
 
 INCLUDES += \
   -I$(srcdir)/../base/src \
   -I$(srcdir)/../html/content/src \
   $(NULL)
 
diff --git a/content/media/MediaEngine.h b/content/media/MediaEngine.h
new file mode 100644
--- /dev/null
+++ b/content/media/MediaEngine.h
@@ -0,0 +1,110 @@
+/* This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this file,
+ * You can obtain one at http://mozilla.org/MPL/2.0/. */
+
+#ifndef MEDIAENGINE_H_
+#define MEDIAENGINE_H_
+
+#include "nsDOMMediaStream.h"
+#include "MediaStreamGraph.h"
+
+namespace mozilla {
+
+/**
+ * Abstract interface for managing audio and video devices. Each platform
+ * must implement a concrete class that will map these classes and methods
+ * to the appropriate backend. For example, on Desktop platforms, these will
+ * correspond to equivalent webrtc (GIPS) calls, and on B2G they will map to
+ * a Gonk interface.
+ */
+class MediaEngineVideoSource;
+class MediaEngineAudioSource;
+
+class MediaEngine
+{
+public:
+  virtual ~MediaEngine() {};
+  
+  /* Populate an array of video sources in the nsTArray. Also include devices
+   * that are currently unavailable. */
+  virtual void EnumerateVideoDevices(nsTArray<nsRefPtr<MediaEngineVideoSource> >*) = 0;
+
+  /* Populate an array of audio sources in the nsTArray. Also include devices
+   * that are currently unavailable. */
+  virtual void EnumerateAudioDevices(nsTArray<nsRefPtr<MediaEngineAudioSource> >*) = 0;
+};
+
+/**
+ * Common abstract base class for audio and video sources.
+ */
+class MediaEngineSource :  public nsISupports
+{
+public:
+  virtual ~MediaEngineSource() {};
+  
+  /* Populate the human readable name of this device in the nsAString */
+  virtual void GetName(nsAString&) = 0;
+
+  /* Populate the UUID of this device in the nsAString */
+  virtual void GetUUID(nsAString&) = 0;
+
+  /* This call reserves but does not start the device. */
+  virtual already_AddRefed<nsDOMMediaStream> Allocate() = 0;
+
+  /* Release the device back to the system. */
+  virtual nsresult Deallocate() = 0;
+
+  /* Start the device and add the track to the provided SourceMediaStream, with
+   * the provided TrackID. You may start appending data to the track
+   * immediately after. */
+  virtual nsresult Start(SourceMediaStream*, TrackID) = 0;
+  
+  /* Stop the device and release the corresponding MediaStream */
+  virtual nsresult Stop() = 0;
+  
+  /* It is an error to call Start() before an Allocate(), and Stop() before
+   * a Start(). Only Allocate() may be called after a Deallocate(). */
+};
+
+/**
+ * Video source and friends.
+ */
+enum MediaEngineVideoCodecType {
+  kVideoCodecH263,
+  kVideoCodecVP8,
+  kVideoCodecI420
+};
+
+struct MediaEngineVideoOptions {
+  PRUint32 mWidth;
+  PRUint32 mHeight;
+  PRUint32 mMaxFPS;
+  MediaEngineVideoCodecType codecType;
+};
+
+class MediaEngineVideoSource : public MediaEngineSource
+{
+public:
+  virtual ~MediaEngineVideoSource() {};
+  
+  /* Return a MediaEngineVideoOptions struct with appropriate values for all
+   * fields. */
+  virtual MediaEngineVideoOptions GetOptions() = 0;
+
+  virtual void Shutdown() = 0;
+};
+
+/**
+ * Audio source and friends.
+ */
+class MediaEngineAudioSource : public MediaEngineSource
+{
+public:
+  virtual ~MediaEngineAudioSource() {};
+
+  virtual void Shutdown() = 0;
+};
+
+}
+
+#endif /* MEDIAENGINE_H_ */
diff --git a/content/media/MediaEngineDefault.cpp b/content/media/MediaEngineDefault.cpp
new file mode 100644
--- /dev/null
+++ b/content/media/MediaEngineDefault.cpp
@@ -0,0 +1,283 @@
+/* This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this file,
+ * You can obtain one at http://mozilla.org/MPL/2.0/. */
+
+#include "MediaEngineDefault.h"
+
+#define WIDTH 320
+#define HEIGHT 240
+#define FPS 10
+#define CHANNELS 1
+
+#define TRACK_VIDEO 1
+#define TRACK_AUDIO 2
+#define RATE USECS_PER_S
+
+namespace mozilla {
+
+NS_IMPL_THREADSAFE_ISUPPORTS1(MediaEngineDefaultVideoSource, nsITimerCallback)
+/**
+ * Default video source.
+ */
+void
+MediaEngineDefaultVideoSource::GetName(nsAString& aName)
+{
+  aName.Assign(NS_LITERAL_STRING("Default Video Device"));
+  return;
+}
+
+void
+MediaEngineDefaultVideoSource::GetUUID(nsAString& aUUID)
+{
+  aUUID.Assign(NS_LITERAL_STRING("1041FCBD-3F12-4F7B-9E9B-1EC556DD5676"));
+  return;
+}
+
+already_AddRefed<nsDOMMediaStream>
+MediaEngineDefaultVideoSource::Allocate()
+{
+  if (mState != kReleased) {
+    return NULL;
+  }
+
+  mState = kAllocated;
+  return nsDOMMediaStream::CreateInputStream();
+}
+
+nsresult
+MediaEngineDefaultVideoSource::Deallocate()
+{
+  if (mState != kStopped && mState != kAllocated) {
+    return NS_ERROR_FAILURE;
+  }
+  mState = kReleased;
+  return NS_OK;
+}
+
+MediaEngineVideoOptions
+MediaEngineDefaultVideoSource::GetOptions()
+{
+  MediaEngineVideoOptions aOpts;
+  aOpts.mWidth = WIDTH;
+  aOpts.mHeight = HEIGHT;
+  aOpts.mMaxFPS = FPS;
+  aOpts.codecType = kVideoCodecI420;
+  return aOpts;
+}
+
+nsresult
+MediaEngineDefaultVideoSource::Start(SourceMediaStream* aStream, TrackID aID)
+{
+  if (mState != kAllocated) {
+    return NULL;
+  }
+
+  mTimer = do_CreateInstance(NS_TIMER_CONTRACTID);
+  if (!mTimer) {
+    return NULL;
+  }
+
+  mSource = aStream;
+
+  // Allocate a single blank Image
+  layers::Image::Format format = layers::Image::PLANAR_YCBCR;
+  mImageContainer = layers::LayerManager::CreateImageContainer();
+    
+  nsRefPtr<layers::Image> image = mImageContainer->CreateImage(&format, 1);
+  
+  int len = ((WIDTH * HEIGHT) * 3 / 2);
+  mImage = static_cast<layers::PlanarYCbCrImage*>(image.get());
+  PRUint8* frame = (PRUint8*) PR_Malloc(len);
+  memset(frame, 0x80, len); // Gray
+
+  const PRUint8 lumaBpp = 8;
+  const PRUint8 chromaBpp = 4; 
+
+  layers::PlanarYCbCrImage::Data data;
+  data.mYChannel = frame;
+  data.mYSize = gfxIntSize(WIDTH, HEIGHT);
+  data.mYStride = WIDTH * lumaBpp / 8.0;
+  data.mCbCrStride = WIDTH * chromaBpp / 8.0;
+  data.mCbChannel = frame + HEIGHT * data.mYStride;
+  data.mCrChannel = data.mCbChannel + HEIGHT * data.mCbCrStride / 2;
+  data.mCbCrSize = gfxIntSize(WIDTH / 2, HEIGHT / 2);
+  data.mPicX = 0;
+  data.mPicY = 0;
+  data.mPicSize = gfxIntSize(WIDTH, HEIGHT);
+  data.mStereoMode = layers::STEREO_MODE_MONO;
+
+  // SetData copies data, so we can free the frame
+  mImage->SetData(data);
+  PR_Free(frame);
+
+  // Set start time to 0
+  mSource->AdvanceKnownTracksTime(0);
+
+  // AddTrack takes ownership of segment
+  VideoSegment *segment = new VideoSegment();
+  segment->AppendFrame(image.forget(), USECS_PER_S / FPS, gfxIntSize(WIDTH, HEIGHT));
+  mSource->AddTrack(aID, RATE, 0, segment);
+
+  // Remember TrackID so we can end it later
+  mTrackID = aID;
+
+  // Start timer for subsequent frames
+  mTimer->InitWithCallback(this, 1000 / FPS, nsITimer::TYPE_REPEATING_SLACK);
+  mState = kStarted;
+  
+  return NS_OK;
+}
+
+nsresult
+MediaEngineDefaultVideoSource::Stop()
+{
+  if (mState != kStarted) {
+    return NS_ERROR_FAILURE;
+  }
+  if (!mTimer) {
+    return NS_ERROR_FAILURE;
+  }
+
+  mTimer->Cancel();
+  mTimer = NULL;
+
+  mSource->EndTrack(mTrackID);
+  mSource->Finish();
+
+  mState = kStopped;
+  return NS_OK;
+}
+
+NS_IMETHODIMP
+MediaEngineDefaultVideoSource::Notify(nsITimer* aTimer)
+{
+  VideoSegment segment;
+
+  // We never add another track to the stream, so we can always advance?
+  // mSource->AdvanceKnownTracksTime(ticksSoFar * RATE);
+
+  nsRefPtr<layers::PlanarYCbCrImage> image = mImage;
+  segment.AppendFrame(image.forget(), USECS_PER_S / FPS, gfxIntSize(WIDTH, HEIGHT));
+  mSource->AppendToTrack(TRACK_VIDEO, &segment);
+
+  return NS_OK;
+}
+
+NS_IMPL_THREADSAFE_ISUPPORTS1(MediaEngineDefaultAudioSource, nsITimerCallback)
+/**
+ * Default audio source.
+ */
+void
+MediaEngineDefaultAudioSource::GetName(nsAString& aName)
+{
+  aName.Assign(NS_LITERAL_STRING("Default Audio Device"));
+  return;
+}
+
+void
+MediaEngineDefaultAudioSource::GetUUID(nsAString& aUUID)
+{
+  aUUID.Assign(NS_LITERAL_STRING("B7CBD7C1-53EF-42F9-8353-73F61C70C092"));
+  return;
+}
+
+already_AddRefed<nsDOMMediaStream>
+MediaEngineDefaultAudioSource::Allocate()
+{
+  if (mState != kReleased) {
+    return NULL;
+  }
+  mState = kAllocated;
+  return nsDOMMediaStream::CreateInputStream();
+}
+
+nsresult
+MediaEngineDefaultAudioSource::Deallocate()
+{
+  if (mState != kStopped && mState != kAllocated) {
+    return NS_ERROR_FAILURE;
+  }
+  mState = kReleased;
+  return NS_OK;
+}
+
+nsresult
+MediaEngineDefaultAudioSource::Start(SourceMediaStream* aStream, TrackID aID)
+{
+  if (mState != kAllocated) {
+    return NULL;
+  }
+
+  mTimer = do_CreateInstance(NS_TIMER_CONTRACTID);
+  if (!mTimer) {
+    return NULL;
+  }
+
+  mSource = aStream;
+
+  // Set start time to 0
+  mSource->AdvanceKnownTracksTime(0);
+
+  // AddTrack will take ownership of segment
+  AudioSegment* segment = new AudioSegment();
+  segment->Init(CHANNELS);
+  mSource->AddTrack(aID, RATE, 0, segment);
+
+  mSource->AdvanceKnownTracksTime(STREAM_TIME_MAX);
+  mTrackID = aID;
+
+  // 1 Audio frame per Video frame.
+  mTimer->InitWithCallback(this, 1000 / FPS, nsITimer::TYPE_REPEATING_SLACK);
+  mState = kStarted;
+
+  return NS_OK;
+}
+
+nsresult
+MediaEngineDefaultAudioSource::Stop()
+{
+  if (mState != kStarted) {
+    return NS_ERROR_FAILURE;
+  }
+  if (!mTimer) {
+    return NS_ERROR_FAILURE;
+  }
+
+  mTimer->Cancel();
+  mTimer = NULL;
+  mState = kStopped;
+  return NS_OK;
+}
+
+NS_IMETHODIMP
+MediaEngineDefaultAudioSource::Notify(nsITimer* aTimer)
+{
+  AudioSegment segment;
+  segment.Init(CHANNELS);
+  segment.InsertNullDataAtStart(1);
+
+  // We never add another track to the stream, so we can always advance?
+  // mSource->AdvanceKnownTracksTime(ticksSoFar * RATE);
+  
+  mSource->AppendToTrack(mTrackID, &segment);
+
+  return NS_OK;
+}
+
+void
+MediaEngineDefault::EnumerateVideoDevices(
+  nsTArray<nsRefPtr<MediaEngineVideoSource> >* aVSources) {
+
+  aVSources->AppendElement(mVSource);
+  return;
+}
+
+void
+MediaEngineDefault::EnumerateAudioDevices(
+  nsTArray<nsRefPtr<MediaEngineAudioSource> >* aASources) {
+  
+  aASources->AppendElement(mASource);
+  return;
+}
+
+}
diff --git a/content/media/MediaEngineDefault.h b/content/media/MediaEngineDefault.h
new file mode 100644
--- /dev/null
+++ b/content/media/MediaEngineDefault.h
@@ -0,0 +1,117 @@
+/* This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this file,
+ * You can obtain one at http://mozilla.org/MPL/2.0/. */
+
+#ifndef MEDIAENGINEDEFAULT_H_
+#define MEDIAENGINEDEFAULT_H_
+
+#include "prmem.h"
+#include "nsITimer.h"
+
+#include "nsCOMPtr.h"
+#include "nsDOMMediaStream.h"
+#include "nsComponentManagerUtils.h"
+
+#include "Layers.h"
+#include "VideoUtils.h"
+#include "MediaEngine.h"
+#include "ImageLayers.h"
+#include "VideoSegment.h"
+#include "AudioSegment.h"
+#include "StreamBuffer.h"
+#include "MediaStreamGraph.h"
+
+namespace mozilla {
+
+/**
+ * The default implementation of the MediaEngine interface.
+ */
+
+enum DefaultEngineState {
+  kAllocated,
+  kStarted,
+  kStopped,
+  kReleased
+};
+
+class MediaEngineDefaultVideoSource : public nsITimerCallback,
+                                      public MediaEngineVideoSource
+                                        
+{
+public:
+  MediaEngineDefaultVideoSource() : mTimer(nsnull), mState(kReleased) {}
+  ~MediaEngineDefaultVideoSource(){};
+
+  virtual void Shutdown() {};
+  virtual void GetName(nsAString&);
+  virtual void GetUUID(nsAString&);
+
+  virtual MediaEngineVideoOptions GetOptions();
+  virtual already_AddRefed<nsDOMMediaStream> Allocate();
+
+  virtual nsresult Deallocate();
+  virtual nsresult Start(SourceMediaStream*, TrackID);
+  virtual nsresult Stop();
+
+  NS_DECL_ISUPPORTS
+  NS_DECL_NSITIMERCALLBACK
+
+protected:
+  TrackID mTrackID;
+  nsCOMPtr<nsITimer> mTimer;
+  nsRefPtr<layers::ImageContainer> mImageContainer;
+
+  DefaultEngineState mState;
+  SourceMediaStream* mSource;
+  layers::PlanarYCbCrImage* mImage;
+};
+
+class MediaEngineDefaultAudioSource : public nsITimerCallback,
+                                      public MediaEngineAudioSource
+                                        
+{
+public:
+  MediaEngineDefaultAudioSource() : mTimer(nsnull), mState(kReleased) {}
+  ~MediaEngineDefaultAudioSource(){};
+  virtual void Shutdown() {};
+
+  virtual void GetName(nsAString&);
+  virtual void GetUUID(nsAString&);
+
+  virtual already_AddRefed<nsDOMMediaStream> Allocate();
+
+  virtual nsresult Deallocate();
+  virtual nsresult Start(SourceMediaStream*, TrackID);
+  virtual nsresult Stop();
+
+  NS_DECL_ISUPPORTS
+  NS_DECL_NSITIMERCALLBACK
+
+protected:
+  nsCOMPtr<nsITimer> mTimer;
+  TrackID mTrackID;
+
+  DefaultEngineState mState;
+  SourceMediaStream* mSource;
+};
+
+class MediaEngineDefault : public MediaEngine
+{
+public:
+  MediaEngineDefault() {
+    mVSource = new MediaEngineDefaultVideoSource();
+    mASource = new MediaEngineDefaultAudioSource();
+  }
+  ~MediaEngineDefault() {}
+
+  virtual void EnumerateVideoDevices(nsTArray<nsRefPtr<MediaEngineVideoSource> >*);
+  virtual void EnumerateAudioDevices(nsTArray<nsRefPtr<MediaEngineAudioSource> >*);
+
+private:
+  nsRefPtr<MediaEngineVideoSource> mVSource;
+  nsRefPtr<MediaEngineAudioSource> mASource;
+};
+
+}
+
+#endif /* NSMEDIAENGINEDEFAULT_H_ */
diff --git a/content/media/MediaEngineWebrtc.cpp b/content/media/MediaEngineWebrtc.cpp
new file mode 100644
--- /dev/null
+++ b/content/media/MediaEngineWebrtc.cpp
@@ -0,0 +1,779 @@
+/* This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this file,
+ * You can obtain one at http://mozilla.org/MPL/2.0/. */
+
+#include "MediaEngineWebrtc.h"
+
+#define CHANNELS 1
+
+namespace mozilla {
+
+/**
+ * Webrtc video source.
+ */
+
+NS_IMPL_THREADSAFE_ISUPPORTS1(MediaEngineWebrtcVideoSource, nsITimerCallback)
+
+/*
+ * Shutdown video renderer and capture threads Async
+ */
+class AsyncShutdownThread : public nsRunnable
+{
+public:
+  AsyncShutdownThread(nsIThread* aThread) : mThread(aThread) {}
+  NS_IMETHODIMP Run() 
+  { 
+  	return mThread->Shutdown(); 
+  }
+private:
+  nsCOMPtr<nsIThread> mThread;
+};
+
+
+
+/**
+ * Runnable to start the capture device
+ */
+class VideoStartCaptureEvent: public nsRunnable
+{
+public:
+  VideoStartCaptureEvent(MediaEngineWebrtcVideoSource* aOwner)
+  {
+  	mOwner = aOwner;
+  }
+
+  NS_IMETHOD Run()
+  {
+  	int error = mOwner->mViERender->AddRenderer(mOwner->mCapIndex, webrtc::kVideoI420, (webrtc::ExternalRenderer*) mOwner);
+  	error = mOwner->mViECapture->StartCapture(mOwner->mCapIndex);
+  	if (-1 == error ) 
+	{
+    	printf( " ERROR in ViECapture::StartCapture %d " , mOwner->mViEBase->LastError());
+    	return NS_ERROR_FAILURE;
+  	}
+
+  	mOwner->mState = kStarted;
+  	error = mOwner->mViERender->StartRender(mOwner->mCapIndex);
+  	if (-1 == error) 
+	{
+    	printf( "ERROR in ViERender::StartRender %d ", mOwner->mViEBase->LastError());
+    	return NS_ERROR_FAILURE;
+  	}
+
+  	return NS_OK; 
+  }
+
+  MediaEngineWebrtcVideoSource* mOwner;
+
+};
+
+/**
+ * Runnable to write the video frames to MediaStream 
+ */
+class VideoRenderToStreamEvent : public nsRunnable
+{
+
+public:
+  VideoRenderToStreamEvent(MediaEngineWebrtcVideoSource* aOwner,
+						   unsigned char* aBuffer, 
+						   int aSize, 
+						   uint32_t aTimestamp,
+						   int64_t aRenderTime)
+  {
+    mOwner = aOwner;
+  	mBuffer = aBuffer;
+    mSize = aSize;
+    mTimestamp = aTimestamp;
+    mRenderTime = aRenderTime;
+  }
+
+  NS_IMETHOD Run()
+  {
+  	 ReentrantMonitorAutoEnter enter(mOwner->mMonitor);
+ 	 // create a VideoFrame and push it to the input stream;
+  	layers::Image::Format format = layers::Image::PLANAR_YCBCR;
+  	nsRefPtr<layers::Image> image = mOwner->mImageContainer->CreateImage(&format, 1);
+  	image->AddRef();
+  	layers::PlanarYCbCrImage* videoImage = static_cast<mozilla::layers::PlanarYCbCrImage*> (image.get());
+  	PRUint8* frame = static_cast<PRUint8*> (mBuffer);
+  	const PRUint8 lumaBpp = 8;
+  	const PRUint8 chromaBpp = 4;
+
+  	layers::PlanarYCbCrImage::Data data;
+  	data.mYChannel = frame;
+  	data.mYSize = gfxIntSize(mOwner->mWidth, mOwner->mHeight);
+  	data.mYStride = mOwner->mWidth * lumaBpp/ 8.0;
+  	data.mCbCrStride = mOwner->mWidth * chromaBpp / 8.0;
+  	data.mCbChannel = frame + mOwner->mHeight * data.mYStride;
+  	data.mCrChannel = data.mCbChannel + mOwner->mHeight * data.mCbCrStride / 2;
+  	data.mCbCrSize = gfxIntSize(mOwner->mWidth/ 2, mOwner->mHeight/ 2);
+  	data.mPicX = 0;
+  	data.mPicY = 0;
+  	data.mPicSize = gfxIntSize(mOwner->mWidth, mOwner->mHeight);
+  	data.mStereoMode = layers::STEREO_MODE_MONO;
+
+  	videoImage->SetData(data);
+
+  	mOwner->mVideoSegment.AppendFrame(videoImage,1, gfxIntSize(mOwner->mWidth, mOwner->mHeight));
+  	mOwner->mSource->AppendToTrack(mOwner->mTrackID, &(mOwner->mVideoSegment));
+	return NS_OK;
+  }
+
+
+  MediaEngineWebrtcVideoSource* mOwner;
+  unsigned char* mBuffer;
+  int mSize;
+  uint32_t mTimestamp;
+  int64_t mRenderTime;
+};
+
+//static initialization
+const unsigned int MediaEngineWebrtcVideoSource::KMaxDeviceNameLength = 128;
+const unsigned int MediaEngineWebrtcVideoSource::KMaxUniqueIdLength = 256;
+
+// Webrtc_External Renderer Implementation
+int
+MediaEngineWebrtcVideoSource::FrameSizeChange(
+  	unsigned int w, unsigned int h, unsigned int streams)
+{
+  mWidth = w;
+  mHeight = h;
+  return 0;
+}
+
+// Webrtc_External Renderer - video frame callback
+int
+MediaEngineWebrtcVideoSource::DeliverFrame(
+  	unsigned char* buffer, int size, uint32_t time_stamp, int64_t render_time)
+{
+ // let our rendering thread deal with the media-streams.
+ nsCOMPtr<nsIRunnable> event = new VideoRenderToStreamEvent(this, buffer, size, time_stamp, render_time); 
+ mVideoRenderingThread->Dispatch(event,0);
+ return 0; 
+}
+
+
+/**
+ * Acquires the basic interfaces for the Video Engine 
+ */
+
+void
+MediaEngineWebrtcVideoSource::Init()
+{
+
+  if(NULL == mVideoEngine)
+  	return;
+
+  mViEBase = webrtc::ViEBase::GetInterface(mVideoEngine);
+  if (NULL == mViEBase ) 
+  {
+    printf( "ERROR in VideoEngine::ViEBase ");
+    return;
+  }
+
+  //get interfaces for capture, render for now
+  mViECapture = webrtc::ViECapture::GetInterface(mVideoEngine);
+  mViERender = webrtc::ViERender::GetInterface(mVideoEngine);
+
+  if(NULL == mViECapture || NULL == mViERender) 
+  	return ;
+
+  if (!mVideoCaptureThread) 
+  {
+   	NS_NewThread(getter_AddRefs(mVideoCaptureThread),
+                 		nsnull,
+                 		MEDIA_THREAD_STACK_SIZE);
+  }
+
+  if (!mVideoRenderingThread) 
+  {
+   	NS_NewThread(getter_AddRefs(mVideoRenderingThread),
+                 		nsnull,
+                 		MEDIA_THREAD_STACK_SIZE);
+  }
+
+  // we should be good here 
+  mInitDone = true;
+}
+
+//XXX: Improve this function ??
+void
+MediaEngineWebrtcVideoSource::GetName(nsAString& aName)
+{
+
+  char deviceName[KMaxDeviceNameLength];
+  memset(deviceName, 0, KMaxDeviceNameLength);
+  char uniqueId[KMaxUniqueIdLength];
+  memset(uniqueId, 0, KMaxUniqueIdLength);
+
+  if(true == mInitDone )
+  {
+  	mViECapture->GetCaptureDevice(
+    	mCapIndex, deviceName, KMaxDeviceNameLength, uniqueId, KMaxUniqueIdLength
+  	);
+
+   aName.Assign(NS_ConvertASCIItoUTF16(deviceName));
+
+  }
+}
+
+//XXX: Improve this function ???
+void
+MediaEngineWebrtcVideoSource::GetUUID(nsAString& aUUID)
+{
+  char deviceName[KMaxDeviceNameLength];
+  memset(deviceName, 0, KMaxDeviceNameLength);
+  char uniqueId[KMaxUniqueIdLength];
+  memset(uniqueId, 0, KMaxUniqueIdLength);
+  if(true == mInitDone) 
+  {
+  	 mViECapture->GetCaptureDevice(
+    		mCapIndex, deviceName, KMaxDeviceNameLength, uniqueId, KMaxUniqueIdLength
+  	);
+
+  	aUUID.Assign(NS_ConvertASCIItoUTF16(uniqueId));
+  }
+}
+
+already_AddRefed<nsDOMMediaStream>
+MediaEngineWebrtcVideoSource::Allocate()
+{
+  if (mState != kReleased) {
+    return NULL;
+  }
+
+  //let's allocate the device
+  char deviceName[KMaxDeviceNameLength];
+  char uniqueId[KMaxUniqueIdLength];
+  memset(deviceName, 0, KMaxDeviceNameLength);
+  memset(uniqueId, 0, KMaxUniqueIdLength);
+  mViECapture->GetCaptureDevice(
+ 				mCapIndex, deviceName, KMaxDeviceNameLength, uniqueId, KMaxUniqueIdLength
+  	);
+
+  if(0 == mViECapture->AllocateCaptureDevice(
+    					uniqueId, KMaxUniqueIdLength, mCapIndex)) {
+  	mState = kAllocated;
+	return nsDOMMediaStream::CreateInputStream();
+  }
+
+  return NULL; 
+}
+
+nsresult
+MediaEngineWebrtcVideoSource::Deallocate()
+{
+  if (mState != kStopped && mState != kAllocated) {
+    return NS_ERROR_FAILURE;
+  }
+  mViECapture->ReleaseCaptureDevice(mCapIndex);
+ 
+  mState = kReleased;
+  return NS_OK;
+}
+
+//XXX: Get rid of the constants
+MediaEngineVideoOptions
+MediaEngineWebrtcVideoSource::GetOptions()
+{
+  MediaEngineVideoOptions aOpts;
+  aOpts.mWidth = mWidth;
+  aOpts.mHeight = mHeight;
+  aOpts.mMaxFPS = mFps;
+  aOpts.codecType = kVideoCodecI420;
+  return aOpts;
+}
+
+// XXX: implement nsIThread here
+nsresult
+MediaEngineWebrtcVideoSource::Start(SourceMediaStream* aStream, TrackID aID)
+{
+  if (false == mInitDone || mState != kAllocated) {
+    return NULL;
+  }
+
+  if(!aStream)
+  	return NULL;
+
+  if(mState == kStarted)
+    return NS_OK;
+
+  mSource = aStream;
+  mTrackID = aID;
+
+  //setup  a blank track
+  mImageContainer = layers::LayerManager::CreateImageContainer();
+  mSource->AddTrack(aID, mFps, 0, new VideoSegment());
+  mSource->AdvanceKnownTracksTime(STREAM_TIME_MAX);
+  
+  nsCOMPtr<nsIRunnable> event = new VideoStartCaptureEvent(this);
+  mVideoCaptureThread->Dispatch(event,0);
+
+  return NS_OK;
+}
+
+
+nsresult
+MediaEngineWebrtcVideoSource::Stop()
+{
+  if (mState != kStarted) {
+    return NS_ERROR_FAILURE;
+  }
+
+
+  mSource->EndTrack(mTrackID);
+  mSource->Finish();
+
+  mViERender->StopRender(mCapIndex);
+  mViERender->RemoveRenderer(mCapIndex);
+  mViECapture->StopCapture(mCapIndex);
+
+  //Stop capture and rendering threads
+  if(mVideoCaptureThread)
+  {
+  	  nsCOMPtr<nsIRunnable> event = new AsyncShutdownThread(mVideoCaptureThread);
+      NS_DispatchToMainThread(event);
+  }
+  
+  if(mVideoRenderingThread)
+  {
+  	  nsCOMPtr<nsIRunnable> event = new AsyncShutdownThread(mVideoRenderingThread);
+      NS_DispatchToMainThread(event);
+  }
+  
+  mState = kStopped;
+  return NS_OK;
+}
+
+void
+MediaEngineWebrtcVideoSource::Shutdown()
+{
+  // Don't clean the mVideoEngine here ...
+  // it is done in MediaEngine class
+  if(false == mInitDone)
+    return;
+
+  if(kStarted == mState)
+  {
+    //there is capture in progress .. 
+    mViERender->StopRender(mCapIndex);
+    mViECapture->StopCapture(mCapIndex);
+    //Stop capture and rendering threads
+    if(mVideoCaptureThread)
+    {
+  	  nsCOMPtr<nsIRunnable> event = new AsyncShutdownThread(mVideoCaptureThread);
+      NS_DispatchToMainThread(event);
+    }
+    if(mVideoRenderingThread)
+    {
+  	  nsCOMPtr<nsIRunnable> event = new AsyncShutdownThread(mVideoRenderingThread);
+      NS_DispatchToMainThread(event);
+    }
+    //mVideoCaptureThread->Shutdown();
+    //mVideoRenderingThread->Shutdown();
+    mViERender->RemoveRenderer(mCapIndex);
+  }
+
+  mViECapture->ReleaseCaptureDevice(mCapIndex);
+
+  //let's clean up the interfaces now
+  mViECapture->Release();
+  mViERender->Release();
+  mViEBase->Release();
+  mState = kReleased;
+  mInitDone = false;
+  
+}
+//XXX: How to get rid of this ??
+NS_IMETHODIMP
+MediaEngineWebrtcVideoSource::Notify(nsITimer* aTimer)
+{
+  return NS_OK;
+}
+
+
+
+/**
+ * Webrtc audio source.
+ */
+
+NS_IMPL_THREADSAFE_ISUPPORTS1(MediaEngineWebrtcAudioSource, nsITimerCallback)
+
+//static initialization
+const unsigned int MediaEngineWebrtcAudioSource::PLAYOUT_SAMPLE_FREQUENCY = 16000;
+const unsigned int MediaEngineWebrtcAudioSource::KMaxDeviceNameLength = 128;
+const unsigned int MediaEngineWebrtcAudioSource::KMaxUniqueIdLength = 128;
+
+
+
+
+// Performs very basic & common initialization 
+void
+MediaEngineWebrtcAudioSource::Init()
+{
+
+  mVoEBase = webrtc::VoEBase::GetInterface(mVoiceEngine);
+  if (NULL == mVoEBase ) 
+  {
+    printf( "ERROR in AudioEngine::VoEBase ");
+    return;
+  }
+
+  //get interfaces for capture, render for now
+  mVoEHw = webrtc::VoEHardware::GetInterface(mVoiceEngine);
+
+  // check if all the interfaces were ok till now
+  if(NULL == mVoEHw) 
+  	return ;
+
+  mChannel = mVoEBase->CreateChannel();
+  if(-1 == mChannel)
+  {
+    printf("\n Couldn't create the channel in AudioEngine ");
+	return;
+  }
+
+  mVoEXmedia = webrtc::VoEExternalMedia::GetInterface(mVoiceEngine);
+  mAudioSegment.Init(CHANNELS);
+  // we should be good by now
+  mInitDone = true;
+
+}
+
+void
+MediaEngineWebrtcAudioSource::GetName(nsAString& aName)
+{
+  char deviceName[KMaxDeviceNameLength];
+  memset(deviceName, 0, KMaxDeviceNameLength);
+  char uniqueId[KMaxUniqueIdLength];
+  memset(uniqueId, 0, KMaxUniqueIdLength);
+  if(true == mInitDone)
+  {
+    mVoEHw->GetRecordingDeviceName(
+        			mCapIndex, deviceName,  uniqueId );
+   aName.Assign(NS_ConvertASCIItoUTF16(deviceName));
+  }
+
+  return;
+}
+
+void
+MediaEngineWebrtcAudioSource::GetUUID(nsAString& aUUID)
+{
+  char deviceName[KMaxDeviceNameLength];
+  memset(deviceName, 0, KMaxDeviceNameLength);
+  char uniqueId[KMaxUniqueIdLength];
+  memset(uniqueId, 0, KMaxUniqueIdLength);
+  if(true == mInitDone )
+  {
+    mVoEHw->GetRecordingDeviceName(
+        			mCapIndex, deviceName,  uniqueId );
+   aUUID.Assign(NS_ConvertASCIItoUTF16(uniqueId));
+  }
+
+  return;
+}
+
+already_AddRefed<nsDOMMediaStream>
+MediaEngineWebrtcAudioSource::Allocate()
+{
+  if (mState != kReleased) {
+    return NULL;
+  }
+  // no special webrtc code to be done , i hope
+  mState = kAllocated;
+  return nsDOMMediaStream::CreateInputStream();
+}
+
+nsresult
+MediaEngineWebrtcAudioSource::Deallocate()
+{
+  if (mState != kStopped && mState != kAllocated) {
+    return NS_ERROR_FAILURE;
+  }
+  mState = kReleased;
+  return NS_OK;
+}
+
+//Loop back audio through media-stream
+nsresult
+MediaEngineWebrtcAudioSource::Start(SourceMediaStream* aStream, TrackID aID)
+{
+  const int DEFAULT_PORT = 55555;
+
+  if (false == mInitDone || mState != kAllocated) {
+    return NULL;
+  }
+
+  if(!aStream)
+  	return NULL;
+
+  mTimer = do_CreateInstance(NS_TIMER_CONTRACTID);
+  if (!mTimer) {
+    return NULL;
+  }
+
+  mSource = aStream;
+
+  AudioSegment* segment = new AudioSegment();
+  segment->Init(CHANNELS);
+  segment->InsertNullDataAtStart(1);
+  mSource->AddTrack(aID, PLAYOUT_SAMPLE_FREQUENCY, 0, segment);
+  mSource->AdvanceKnownTracksTime(STREAM_TIME_MAX);
+  mTrackID = aID;
+
+  printf("\n Starting the audio engine ");
+  mVoEBase->SetLocalReceiver(mChannel,DEFAULT_PORT);
+  mVoEBase->SetSendDestination(mChannel,DEFAULT_PORT,"127.0.0.1");
+
+  if(-1 == mVoEXmedia->SetExternalPlayoutStatus(true))
+  	return NULL;
+  
+  mVoEBase->StartPlayout(mChannel);
+  mVoEBase->StartSend(mChannel);
+  mVoEBase->StartReceive(mChannel);
+   
+  mState = kStarted;
+
+  // call every 10 milliseconds
+  mTimer->InitWithCallback(this, 10, nsITimer::TYPE_REPEATING_SLACK);
+
+  return NS_OK;
+}
+
+nsresult
+MediaEngineWebrtcAudioSource::Stop()
+{
+  if (mState != kStarted) {
+    return NS_ERROR_FAILURE;
+  }
+  if (!mTimer) {
+    return NS_ERROR_FAILURE;
+  }
+
+  if(!mVoEBase) {
+    return NS_ERROR_FAILURE;
+  }
+
+  mVoEBase->StopReceive(mChannel);
+  mVoEBase->StopSend(mChannel);
+  mVoEBase->StopPlayout(mChannel); 
+
+  mTimer->Cancel();
+  mTimer = NULL;
+  mState = kStopped;
+  return NS_OK;
+}
+
+void
+MediaEngineWebrtcAudioSource::Shutdown()
+{
+  // Don't clean the mVoiceEngine here ...
+  // it is done in MediaEngine class
+
+  if(false == mInitDone)
+  	return;
+
+  if(kStarted == mState)
+  {
+  	//Stop External playout
+  	mVoEBase->StopReceive(mChannel);
+  	mVoEBase->StopSend(mChannel);
+  	mVoEBase->StopPlayout(mChannel);
+  	mTimer->Cancel();
+  	mTimer = NULL;
+  }
+
+  mVoEBase->Terminate();
+  mVoEXmedia->Release();
+  mVoEHw->Release();
+  mVoEBase->Release();
+  mState = kReleased;
+  mInitDone = false;
+ 
+}
+
+//XXX: Array size - make it more smarter than just 160
+//XXX: Improve this function
+
+NS_IMETHODIMP
+MediaEngineWebrtcAudioSource::Notify(nsITimer* aTimer)
+{
+  // just one audio sample
+  const int AUDIO_SAMPLE_LENGTH = 160;
+  static int16_t audio10ms[AUDIO_SAMPLE_LENGTH];
+  int sample_length  =0;
+
+  memset(audio10ms, 0, AUDIO_SAMPLE_LENGTH * sizeof(short));
+
+  mVoEXmedia->ExternalPlayoutGetData(audio10ms, PLAYOUT_SAMPLE_FREQUENCY, 100, sample_length); 
+  if(sample_length == 0)
+  {
+  	printf("\n Audio Sample lenth is 0 ");
+	return NS_OK;
+  }
+
+  // allocate shared buffer of lenght bytes
+  int buff_size = AUDIO_SAMPLE_LENGTH * sizeof(short);
+  nsRefPtr<SharedBuffer> buffer = SharedBuffer::Create(buff_size);
+  buffer->AddRef();
+  int16_t* dest = static_cast<int16_t*>(buffer->Data());
+  for(int i=0; i < sample_length; i++)
+  {
+	dest[i] = audio10ms[i];
+  }
+
+  mAudioSegment.AppendFrames(buffer.forget(), sample_length, 0, sample_length, nsAudioStream::FORMAT_S16_LE);
+  mSource->AppendToTrack(mTrackID, &mAudioSegment);
+  return NS_OK;
+}
+
+//XXX: Not multi-threded and non-renterant -???
+void
+MediaEngineWebrtc::EnumerateVideoDevices(nsTArray<nsRefPtr<MediaEngineVideoSource> >* aVSources)
+{
+  int error = 0;
+  printf("\n EnumerateVideo Devices ");
+
+  //we can use it function locals .. no need to save it in the class
+  webrtc::ViEBase* ptrViEBase;
+  webrtc::ViECapture* ptrViECapture;
+  
+  if(NULL == mVideoEngine)
+  {
+      mVideoEngine = webrtc::VideoEngine::Create();
+      if (NULL == mVideoEngine ) 
+	{
+         printf( "ERROR in VideoEngine::Create\n");
+    	   return;
+     }
+  }
+
+  // te should have VideoEngine Created here
+  ptrViEBase = webrtc::ViEBase::GetInterface(mVideoEngine);
+  if (NULL == ptrViEBase) {
+    return;
+  }
+
+
+  if( false == mVideoEngineInit)
+  {
+  	error = ptrViEBase->Init();
+  	if (-1 == error ) {
+   	 printf( "ERROR in VideoEngine::Init\n");
+   	 return;
+  	}
+    mVideoEngineInit = true;
+  }
+
+  ptrViECapture = webrtc::ViECapture::GetInterface(mVideoEngine);
+  if (NULL == ptrViECapture ) {
+    printf("ERROR in ViECapture::GetInterface\n");
+    return;
+  }
+
+  int num = ptrViECapture->NumberOfCaptureDevices();
+  if (num <= 0) {
+    printf( "ERROR no video devices found\n");
+    return;
+  } else {
+    printf("GetUserMedia:: Found %d devices!\n", num);
+  }
+ 
+  for(int i=0; i < num; i++)
+  {
+    //let's create VideoSouce objects
+    aVSources->AppendElement( new MediaEngineWebrtcVideoSource(mVideoEngine , i));
+  }
+
+  // safe to release local interfaces on the engine
+   ptrViEBase->Release();
+   ptrViECapture->Release();
+
+  return;
+}
+
+void
+MediaEngineWebrtc::EnumerateAudioDevices(nsTArray<nsRefPtr<MediaEngineAudioSource> >* aASources)
+{
+  
+  // Be sure to release these at the end of the function
+  // safety measure though
+  webrtc::VoEBase* ptrVoEBase = NULL;
+  webrtc::VoEHardware* ptrVoEHw = NULL;
+  int error = 0; 
+  printf(" Enumerate Audio Devices ");
+ 
+  if(NULL == mVoiceEngine)
+  {
+    mVoiceEngine = webrtc::VoiceEngine::Create();
+    if(NULL == mVoiceEngine)
+    {	
+	printf(" Unable to create voice engine ");
+	return;
+    }
+  }  
+
+  // all interfaces pointers are ref-counted 
+  // we should be good on mutiple calls to this function ..
+  ptrVoEBase = webrtc::VoEBase::GetInterface( mVoiceEngine );
+  if(NULL == ptrVoEBase)
+  {
+	printf(" VoEBase creation failed ");
+	return;
+  }   
+
+  //Init the voice library for the common parts
+  if(false == mAudioEngineInit)
+  {
+	error = ptrVoEBase->Init();
+	if(-1 == error)
+	{
+		printf("\n Audio Engine Init Failed ");
+	}
+	mAudioEngineInit = true;
+  } 
+
+  ptrVoEHw = webrtc::VoEHardware::GetInterface(mVoiceEngine);
+  if(NULL == ptrVoEHw)
+  {
+	printf("\n Unable to get Audio Hardware Interface ");
+    return;
+  }
+
+  //let's enumerate audio input devices
+  int nDevices = 0;
+  error = ptrVoEHw->GetNumOfRecordingDevices(nDevices);
+  for(int i = 0; i < nDevices; i++) 
+  {
+   	char deviceName[128];
+  	memset(deviceName, 0, 128);
+  	char uniqueId[128];
+  	memset(uniqueId, 0, 128);
+   	ptrVoEHw->GetRecordingDeviceName(i, deviceName,  uniqueId );
+  	aASources->AppendElement(new MediaEngineWebrtcAudioSource(mVoiceEngine,i));
+  } 
+
+  // releasing them to re-set the reference count ... 
+  ptrVoEHw->Release(); 
+  ptrVoEBase->Release();
+
+}
+
+
+void
+MediaEngineWebrtc::Shutdown()
+{
+
+  //delete video engine
+  if(mVideoEngine)
+  if(false == webrtc::VideoEngine::Delete(mVideoEngine))
+  	printf("\n Video Engine Delete Failed ");
+
+  //delete audio engine
+  if(mVoiceEngine)
+  if(false == webrtc::VoiceEngine::Delete(mVoiceEngine))
+	printf("\n Audio Engine Delete Failed ");
+}
+
+}
diff --git a/content/media/MediaEngineWebrtc.h b/content/media/MediaEngineWebrtc.h
new file mode 100644
--- /dev/null
+++ b/content/media/MediaEngineWebrtc.h
@@ -0,0 +1,249 @@
+/* This Source Code Form is subject to the terms of the Mozilla Public
+ * License, v. 2.0. If a copy of the MPL was not distributed with this file,
+ * You can obtain one at http://mozilla.org/MPL/2.0/. */
+
+#ifndef MEDIAENGINEWEBRTC_H_
+#define MEDIAENGINEWEBRTC_H_
+
+#include "prmem.h"
+#include "nsITimer.h"
+#include "nsIThread.h"
+#include "nsIRunnable.h"
+
+
+#include "nsCOMPtr.h"
+#include "nsDOMMediaStream.h"
+#include "nsComponentManagerUtils.h"
+
+#include "prthread.h"
+#include "nsThreadUtils.h"
+#include "Layers.h"
+#include "VideoUtils.h"
+#include "MediaEngine.h"
+#include "ImageLayers.h"
+#include "VideoSegment.h"
+#include "AudioSegment.h"
+#include "StreamBuffer.h"
+#include "MediaStreamGraph.h"
+
+//Webrtc Inlcudes - GUM Specific
+// Audio Engine Includes
+#include "voice_engine/main/interface/voe_base.h"
+#include "voice_engine/main/interface/voe_hardware.h"
+#include "voice_engine/main/interface/voe_audio_processing.h"
+#include "voice_engine/main/interface/voe_volume_control.h"
+#include "voice_engine/main/interface/voe_external_media.h"
+// Video Engine Includes
+#include "video_engine/include/vie_base.h"
+#include "video_engine/include/vie_codec.h"
+#include "video_engine/include/vie_render.h"
+#include "video_engine/include/vie_capture.h"
+
+
+
+namespace mozilla {
+
+/**
+ * The webrtc implementation of the MediaEngine interface.
+ */
+
+enum WebrtcEngineState {
+  kAllocated,
+  kStarted,
+  kStopped,
+  kReleased,
+};
+
+//Foreward declarations
+class VideoStartCaptureEvent;
+class VideoRenderToStreamEvent;
+
+//Webrtc Video Subsystem abstraction
+
+class MediaEngineWebrtcVideoSource : public nsITimerCallback,
+				     public MediaEngineVideoSource,
+				     public webrtc::ExternalRenderer 
+
+{
+public:
+
+  // ViEExternalRenderer implementation
+  virtual int FrameSizeChange(
+        unsigned int, unsigned int, unsigned int
+  );
+
+ virtual int DeliverFrame(
+        unsigned char*,int, uint32_t , int64_t
+  );
+
+ explicit MediaEngineWebrtcVideoSource(webrtc::VideoEngine* videoEnginePtr,
+					int index, int aFps = 30) 
+					: mTimer(nsnull),
+				          mVideoCaptureThread(nsnull),
+					  mVideoRenderingThread(nsnull),
+					  mVideoEngine(videoEnginePtr),
+					  mCapIndex(index),
+					  mWidth(352),
+					  mHeight(288),
+					  mState(kReleased),
+					  mMonitor("WebrtcCamera.Monitor"),
+					  mFps(aFps),
+					  mInitDone(false) { 
+		//XXX: eventually move this out of constructor
+		Init();
+   }
+
+  ~MediaEngineWebrtcVideoSource()
+  {
+	//printf("\n Video Source Destructor Invoked ");
+  }
+  // Granular control for engine cleanup
+  virtual void Shutdown();
+ 
+  virtual void GetName(nsAString&);
+  virtual void GetUUID(nsAString&);
+  virtual MediaEngineVideoOptions GetOptions();
+  virtual already_AddRefed<nsDOMMediaStream> Allocate();
+  virtual nsresult Deallocate();
+  virtual nsresult Start(SourceMediaStream*, TrackID);
+  virtual nsresult Stop();
+
+
+  NS_DECL_ISUPPORTS
+  NS_DECL_NSITIMERCALLBACK
+
+protected:
+ 
+  
+  nsCOMPtr<nsITimer> mTimer; // not used 
+  nsCOMPtr<nsIThread> mVideoCaptureThread; // QT Run loop for capture needs a thread
+  nsCOMPtr<nsIThread> mVideoRenderingThread; // in video-frames to media-stream
+
+private:
+  friend class VideoStartCaptureEvent;
+  friend class VideoRenderToStreamEvent;
+  
+  //statics
+  static const unsigned int KMaxDeviceNameLength;
+  static const unsigned int KMaxUniqueIdLength;
+  
+  // Initialize the needed Video engine interfaces
+  void Init();
+
+  //GUM needs
+  webrtc::VideoEngine* mVideoEngine; // weak reference .. dont delete it here
+  webrtc::ViEBase* mViEBase;
+  webrtc::ViECapture* mViECapture;
+  webrtc::ViERender* mViERender;
+  webrtc::CaptureCapability mCaps; //doesn't work on OSX
+
+  //capture index for the associated device
+  int mCapIndex;
+  int mWidth, mHeight;
+  TrackID mTrackID;
+
+  WebrtcEngineState mState;
+  mozilla::ReentrantMonitor mMonitor; //Monitor for processing webrtc frames
+  SourceMediaStream* mSource; //in video-frames 
+  int mFps;  // track rate - 30 fps default
+  bool mInitDone;
+  nsRefPtr<layers::ImageContainer> mImageContainer;
+  VideoSegment mVideoSegment;
+};
+
+class MediaEngineWebrtcAudioSource : public nsITimerCallback,
+                                     public MediaEngineAudioSource
+{
+public:
+
+  static const unsigned int PLAYOUT_SAMPLE_FREQUENCY; //default is 16000
+  
+  explicit MediaEngineWebrtcAudioSource(webrtc::VoiceEngine* voiceEngine,
+						int aIndex) 
+						: mTimer(nsnull),
+						  mVoiceEngine(voiceEngine),
+						  mMonitor("WebrtcAIn.Monitor"),
+						  mCapIndex(aIndex), 
+						  mChannel(-1),
+						  mInitDone(false),
+					          mState(kReleased) {
+    	//XXX: Eventually move out of constructor
+		Init();		
+	}
+
+  ~MediaEngineWebrtcAudioSource(){};
+
+  virtual void Shutdown();
+  virtual void GetName(nsAString&);
+  virtual void GetUUID(nsAString&);
+
+  virtual already_AddRefed<nsDOMMediaStream> Allocate();
+  virtual nsresult Deallocate();
+  virtual nsresult Start(SourceMediaStream*, TrackID);
+  virtual nsresult Stop();
+
+  NS_DECL_ISUPPORTS
+  NS_DECL_NSITIMERCALLBACK
+
+protected:
+  nsCOMPtr<nsITimer> mTimer; // 10ms audio samples timer
+
+private:
+  //statics
+  static const unsigned int KMaxDeviceNameLength;
+  static const unsigned int KMaxUniqueIdLength;
+  
+  void Init(); //Initialize voice engine interfaces
+
+  //we don't need ref-couting since engine does it for us
+  webrtc::VoiceEngine* mVoiceEngine; 
+  webrtc::VoEBase* mVoEBase;
+  webrtc::VoEHardware* mVoEHw;
+  webrtc::VoEExternalMedia* mVoEXmedia; // external playout 
+
+  mozilla::ReentrantMonitor mMonitor; //audio-frame processing (???)
+  int mCapIndex;
+  int mChannel;
+  TrackID mTrackID;
+  bool mInitDone;
+  WebrtcEngineState mState;
+  SourceMediaStream* mSource;
+  AudioSegment mAudioSegment;
+  
+};
+
+class MediaEngineWebrtc : public MediaEngine
+{
+public:
+  MediaEngineWebrtc():mVideoEngine(NULL),
+			  mVoiceEngine(NULL),
+			  mVideoEngineInit(false),
+		          mAudioEngineInit(false) {
+  }
+
+  ~MediaEngineWebrtc() {
+	Shutdown();
+  }
+
+  //Client's should ensure to clean-up sources video/audio sources
+  //before invoking Shutdown on this class.
+  void Shutdown();
+  virtual void EnumerateVideoDevices(nsTArray<nsRefPtr<MediaEngineVideoSource> >*);
+  virtual void EnumerateAudioDevices(nsTArray<nsRefPtr<MediaEngineAudioSource> >*);
+
+
+private:
+  //video engine instance pointer 
+  webrtc::VideoEngine* mVideoEngine;
+  //audio engine instace pointer
+  webrtc::VoiceEngine* mVoiceEngine;	
+
+  // need this to avoid unneccesary webrtc calls while enumerating
+  bool mVideoEngineInit;
+  bool mAudioEngineInit;
+
+};
+
+}
+
+#endif /* NSMEDIAENGINEWEBRTC_H_ */
